{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ec51f656",
      "metadata": {
        "id": "ec51f656"
      },
      "source": [
        "## <b>RAG with Azure OpenAI<b>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d271891",
      "metadata": {},
      "source": [
        "### Prerequisite package installation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f887e825",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ! pip install llama-index-embeddings-azure-openai\n",
        "# ! pip install llama-index-llms-azure-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "454e9cf3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ! pip install llama-index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1c48378",
      "metadata": {},
      "source": [
        "###  Loading Dotenv package to load environment variables from .env file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "id": "45515c96",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 154,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "710d6708",
      "metadata": {
        "id": "710d6708"
      },
      "source": [
        "### Loading Necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "id": "b05e71d5",
      "metadata": {
        "id": "b05e71d5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from llama_index.llms.azure_openai import AzureOpenAI\n",
        "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader,StorageContext,load_index_from_storage,get_response_synthesizer\n",
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(\n",
        "    stream=sys.stdout, level=logging.INFO\n",
        ")  # logging.DEBUG for more verbose output\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcaaafdf",
      "metadata": {
        "id": "fcaaafdf"
      },
      "source": [
        "Here, we setup the embedding model (for retrieval) and llm (for text generation).\n",
        "Note that you need not only model names (e.g. \"text-embedding-ada-002\"), but also model deployment names (the one you chose when deploying the model in Azure.\n",
        "You must pass the deployment name as a parameter when you initialize `AzureOpenAI` and `OpenAIEmbedding`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b1b14cb",
      "metadata": {},
      "source": [
        "### Initializing the AzureOpenAI and OpenAIEmbedding models "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "id": "e2569cb0",
      "metadata": {
        "id": "e2569cb0"
      },
      "outputs": [],
      "source": [
        "api_key = os.getenv('AZURE_API_KEY')\n",
        "azure_endpoint = os.getenv('AZURE_ENDPOINT')\n",
        "api_version = \"2023-07-01-preview\"\n",
        "\n",
        "llm = AzureOpenAI(\n",
        "    model=\"gpt-35-turbo\",\n",
        "    deployment_name=\"gpt-35-turbo\",\n",
        "    api_key=api_key,\n",
        "    azure_endpoint=azure_endpoint,\n",
        "    api_version=api_version,\n",
        "    temperature=0.4,\n",
        "    max_tokens=200\n",
        ")\n",
        "\n",
        "# You need to deploy your own embedding model as well as your own chat completion model\n",
        "embed_model = AzureOpenAIEmbedding(\n",
        "    model=\"text-embedding-ada-002\",\n",
        "    deployment_name=\"text-embedding-ada-002\",\n",
        "    api_key=api_key,\n",
        "    azure_endpoint=azure_endpoint,\n",
        "    api_version=api_version\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "id": "72aac5a6-495e-40d2-82d3-bda8688ae919",
      "metadata": {
        "id": "72aac5a6-495e-40d2-82d3-bda8688ae919"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "id": "dac661a2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AzureOpenAI(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x0000022A4F3A8450>, system_prompt=None, messages_to_prompt=<function messages_to_prompt at 0x0000022A66D196C0>, completion_to_prompt=<function default_completion_to_prompt at 0x0000022A66D9E980>, output_parser=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>, query_wrapper_prompt=None, model='gpt-35-turbo', temperature=0.4, max_tokens=200, additional_kwargs={}, max_retries=3, timeout=60.0, default_headers=None, reuse_client=True, api_key='d63a5e9efcbf4026975ce9e3e0b4a7af', api_base='https://api.openai.com/v1', api_version='2023-07-01-preview', engine='gpt-35-turbo', azure_endpoint='https://mathurai.openai.azure.com/', azure_deployment=None, use_azure_ad=False)"
            ]
          },
          "execution_count": 158,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "id": "c536e4aa",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AzureOpenAIEmbedding(model_name='text-embedding-ada-002', embed_batch_size=10, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x0000022A4F3A8450>, additional_kwargs={}, api_key='d63a5e9efcbf4026975ce9e3e0b4a7af', api_base='https://api.openai.com/v1', api_version='2023-07-01-preview', max_retries=10, timeout=60.0, default_headers=None, reuse_client=True, dimensions=None, azure_endpoint='https://mathurai.openai.azure.com/', azure_deployment='text-embedding-ada-002')"
            ]
          },
          "execution_count": 159,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embed_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "852a7f46",
      "metadata": {},
      "source": [
        "### Data Ingestion from source directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "id": "07a94833",
      "metadata": {},
      "outputs": [],
      "source": [
        "documents = SimpleDirectoryReader(\"./data\").load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "id": "575b339e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "execution_count": 161,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdb943fd",
      "metadata": {},
      "source": [
        "### Splitting documents into chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "id": "f26c59db",
      "metadata": {},
      "outputs": [],
      "source": [
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "parser = SentenceSplitter(chunk_size=100,chunk_overlap=0)\n",
        "\n",
        "nodes = parser.get_nodes_from_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "id": "c52c5e73",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "230"
            ]
          },
          "execution_count": 163,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce980fb5",
      "metadata": {},
      "source": [
        "### Importing FAISS Vector Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "id": "8857df18",
      "metadata": {},
      "outputs": [],
      "source": [
        "from llama_index.vector_stores.faiss import FaissVectorStore\n",
        "from IPython.display import Markdown, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "id": "08617e42",
      "metadata": {},
      "outputs": [],
      "source": [
        "import faiss\n",
        "\n",
        "# dimensions of text-ada-embedding-002\n",
        "d = 1536\n",
        "\n",
        "# Creating an index with flat indices and metric as 'Cosine similarity' (IP: Inner Product)\n",
        "faiss_index= faiss.IndexFlatIP(d)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d80c05f2",
      "metadata": {},
      "source": [
        "### Indexing the documents and creating the vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "id": "158b052f",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:   0%|          | 0/230 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:   4%|▍         | 10/230 [00:01<00:42,  5.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:   9%|▊         | 20/230 [00:02<00:23,  9.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  13%|█▎        | 30/230 [00:03<00:18, 10.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  17%|█▋        | 40/230 [00:03<00:15, 12.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  22%|██▏       | 50/230 [00:04<00:13, 13.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  26%|██▌       | 60/230 [00:05<00:11, 14.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  30%|███       | 70/230 [00:05<00:10, 14.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  35%|███▍      | 80/230 [00:06<00:09, 15.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  39%|███▉      | 90/230 [00:06<00:08, 15.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  43%|████▎     | 100/230 [00:07<00:08, 15.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  48%|████▊     | 110/230 [00:08<00:07, 16.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  52%|█████▏    | 120/230 [00:08<00:06, 17.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  57%|█████▋    | 130/230 [00:09<00:05, 17.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  61%|██████    | 140/230 [00:09<00:05, 17.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  65%|██████▌   | 150/230 [00:10<00:04, 17.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  70%|██████▉   | 160/230 [00:10<00:03, 20.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  74%|███████▍  | 170/230 [00:11<00:02, 20.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  78%|███████▊  | 180/230 [00:11<00:02, 19.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  83%|████████▎ | 190/230 [00:12<00:02, 19.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  87%|████████▋ | 200/230 [00:12<00:01, 19.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  91%|█████████▏| 210/230 [00:13<00:01, 19.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  96%|█████████▌| 220/230 [00:13<00:00, 19.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings: 100%|██████████| 230/230 [00:14<00:00, 16.20it/s]\n"
          ]
        }
      ],
      "source": [
        "vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
        "\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "index = VectorStoreIndex(\n",
        "    nodes=nodes,\n",
        "    storage_context=storage_context, \n",
        "    embed_model=embed_model, \n",
        "    show_progress=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "id": "c8e19705",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "StorageContext(docstore=<llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore object at 0x0000022A6B604350>, index_store=<llama_index.core.storage.index_store.simple_index_store.SimpleIndexStore object at 0x0000022A6B604C90>, vector_stores={'default': FaissVectorStore(stores_text=False, is_embedding_query=True), 'image': <llama_index.core.vector_stores.simple.SimpleVectorStore object at 0x0000022A6B604650>}, graph_store=<llama_index.core.graph_stores.simple.SimpleGraphStore object at 0x0000022A6B605490>)\n"
          ]
        }
      ],
      "source": [
        "print(storage_context)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9d84cc3",
      "metadata": {},
      "source": [
        "### Storing the index on the disk for future use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "id": "07e75b7d",
      "metadata": {},
      "outputs": [],
      "source": [
        "index.storage_context.persist()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fd1e08d",
      "metadata": {},
      "source": [
        "### Loading the index from the disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "id": "47d227a5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:root:Loading llama_index.vector_stores.faiss.base from ./storage\\default__vector_store.json.\n",
            "Loading llama_index.vector_stores.faiss.base from ./storage\\default__vector_store.json.\n",
            "Loading llama_index.vector_stores.faiss.base from ./storage\\default__vector_store.json.\n",
            "Loading llama_index.vector_stores.faiss.base from ./storage\\default__vector_store.json.\n",
            "Loading llama_index.vector_stores.faiss.base from ./storage\\default__vector_store.json.\n",
            "INFO:llama_index.core.indices.loading:Loading all indices.\n",
            "Loading all indices.\n",
            "Loading all indices.\n",
            "Loading all indices.\n",
            "Loading all indices.\n"
          ]
        }
      ],
      "source": [
        "# load index from disk\n",
        "vector_store = FaissVectorStore.from_persist_dir(\"./storage\")\n",
        "storage_context = StorageContext.from_defaults(\n",
        "    vector_store=vector_store, persist_dir=\"./storage\"\n",
        ")\n",
        "index = load_index_from_storage(storage_context=storage_context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "id": "f43fe3a2",
      "metadata": {},
      "outputs": [],
      "source": [
        "retriever = VectorIndexRetriever(\n",
        "    index=index,\n",
        "    similarity_top_k=10,\n",
        ")\n",
        "response_synthesizer = get_response_synthesizer()\n",
        "\n",
        "query_engine = RetrieverQueryEngine(\n",
        "    retriever=retriever,\n",
        "    response_synthesizer=response_synthesizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "fb4b0b60",
      "metadata": {},
      "outputs": [],
      "source": [
        "from llama_index.core.evaluation import FaithfulnessEvaluator\n",
        "evaluator = FaithfulnessEvaluator(llm=llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\"who is the president of india\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "id": "6fa154c7",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "<b>I'm sorry, I cannot answer that question as it is not related to the provided context information about life insurance and personal information.</b>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Markdown(f\"<b>{response}</b>\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "id": "1145e69c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\"what was the previous answer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "id": "d1b53f90",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "<b>There is no previous answer provided in the given context information.</b>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Markdown(f\"<b>{response}</b>\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
