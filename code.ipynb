{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ec51f656",
      "metadata": {
        "id": "ec51f656"
      },
      "source": [
        "## <b>RAG with Azure OpenAI<b>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d271891",
      "metadata": {},
      "source": [
        "### Prerequisite package installation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f887e825",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ! pip install llama-index-embeddings-azure-openai\n",
        "# ! pip install llama-index-llms-azure-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "454e9cf3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ! pip install llama-index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1c48378",
      "metadata": {},
      "source": [
        "###  Loading Dotenv package to load environment variables from .env file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "45515c96",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "710d6708",
      "metadata": {
        "id": "710d6708"
      },
      "source": [
        "### Loading Necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b05e71d5",
      "metadata": {
        "id": "b05e71d5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from llama_index.llms.azure_openai import AzureOpenAI\n",
        "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader,StorageContext,load_index_from_storage,get_response_synthesizer\n",
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(\n",
        "    stream=sys.stdout, level=logging.INFO\n",
        ")  # logging.DEBUG for more verbose output\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcaaafdf",
      "metadata": {
        "id": "fcaaafdf"
      },
      "source": [
        "Here, we setup the embedding model (for retrieval) and llm (for text generation).\n",
        "Note that you need not only model names (e.g. \"text-embedding-ada-002\"), but also model deployment names (the one you chose when deploying the model in Azure.\n",
        "You must pass the deployment name as a parameter when you initialize `AzureOpenAI` and `OpenAIEmbedding`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b1b14cb",
      "metadata": {},
      "source": [
        "### Initializing the AzureOpenAI and OpenAIEmbedding models "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e2569cb0",
      "metadata": {
        "id": "e2569cb0"
      },
      "outputs": [],
      "source": [
        "api_key = os.getenv('AZURE_API_KEY')\n",
        "azure_endpoint = os.getenv('AZURE_ENDPOINT')\n",
        "api_version = \"2023-07-01-preview\"\n",
        "\n",
        "llm = AzureOpenAI(\n",
        "    model=\"gpt-4\",\n",
        "    deployment_name=\"gpt-4\",\n",
        "    api_key=api_key,\n",
        "    azure_endpoint=azure_endpoint,\n",
        "    api_version=api_version,\n",
        "    temperature=0.4,\n",
        "    max_tokens=500\n",
        ")\n",
        "\n",
        "# You need to deploy your own embedding model as well as your own chat completion model\n",
        "embed_model = AzureOpenAIEmbedding(\n",
        "    model=\"text-embedding-ada-002\",\n",
        "    deployment_name=\"text-embedding-ada-002\",\n",
        "    api_key=api_key,\n",
        "    azure_endpoint=azure_endpoint,\n",
        "    api_version=api_version\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "72aac5a6-495e-40d2-82d3-bda8688ae919",
      "metadata": {
        "id": "72aac5a6-495e-40d2-82d3-bda8688ae919"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e1d9386c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/gpt-4/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/gpt-4/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        }
      ],
      "source": [
        "response=llm.complete(\"Wheels on the bus go...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "35cdb323",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CompletionResponse(text='The wheels on the bus go round and round, round and round, round and round.', additional_kwargs={}, raw={'id': 'chatcmpl-90bBKz1XGvtPFmq4M9TE5IN3o2G9x', 'choices': [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The wheels on the bus go round and round, round and round, round and round.', role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], 'created': 1709929954, 'model': 'gpt-4', 'object': 'chat.completion', 'system_fingerprint': 'fp_8abb16fa4e', 'usage': CompletionUsage(completion_tokens=18, prompt_tokens=14, total_tokens=32), 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}]}, delta=None)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "852a7f46",
      "metadata": {},
      "source": [
        "### Data Ingestion from source directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "07a94833",
      "metadata": {},
      "outputs": [],
      "source": [
        "documents = SimpleDirectoryReader(\"./data\").load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "575b339e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdb943fd",
      "metadata": {},
      "source": [
        "### Splitting documents into chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "f26c59db",
      "metadata": {},
      "outputs": [],
      "source": [
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "parser = SentenceSplitter(chunk_size=100,chunk_overlap=0)\n",
        "\n",
        "nodes = parser.get_nodes_from_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c52c5e73",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "230"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce980fb5",
      "metadata": {},
      "source": [
        "### Importing FAISS Vector Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "8857df18",
      "metadata": {},
      "outputs": [],
      "source": [
        "from llama_index.vector_stores.faiss import FaissVectorStore\n",
        "from IPython.display import Markdown, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "08617e42",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:faiss.loader:Loading faiss with AVX2 support.\n",
            "Loading faiss with AVX2 support.\n",
            "INFO:faiss.loader:Successfully loaded faiss with AVX2 support.\n",
            "Successfully loaded faiss with AVX2 support.\n"
          ]
        }
      ],
      "source": [
        "import faiss\n",
        "\n",
        "# dimensions of text-ada-embedding-002\n",
        "d = 1536\n",
        "\n",
        "# Creating an index with flat indices and metric as 'Cosine similarity' (IP: Inner Product)\n",
        "faiss_index= faiss.IndexFlatIP(d)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d80c05f2",
      "metadata": {},
      "source": [
        "### Indexing the documents and creating the vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "id": "158b052f",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:   0%|          | 0/230 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:   4%|▍         | 10/230 [00:01<00:42,  5.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:   9%|▊         | 20/230 [00:02<00:23,  9.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  13%|█▎        | 30/230 [00:03<00:18, 10.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  17%|█▋        | 40/230 [00:03<00:15, 12.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  22%|██▏       | 50/230 [00:04<00:13, 13.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  26%|██▌       | 60/230 [00:05<00:11, 14.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  30%|███       | 70/230 [00:05<00:10, 14.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  35%|███▍      | 80/230 [00:06<00:09, 15.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  39%|███▉      | 90/230 [00:06<00:08, 15.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  43%|████▎     | 100/230 [00:07<00:08, 15.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  48%|████▊     | 110/230 [00:08<00:07, 16.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  52%|█████▏    | 120/230 [00:08<00:06, 17.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  57%|█████▋    | 130/230 [00:09<00:05, 17.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  61%|██████    | 140/230 [00:09<00:05, 17.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  65%|██████▌   | 150/230 [00:10<00:04, 17.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  70%|██████▉   | 160/230 [00:10<00:03, 20.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  74%|███████▍  | 170/230 [00:11<00:02, 20.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  78%|███████▊  | 180/230 [00:11<00:02, 19.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  83%|████████▎ | 190/230 [00:12<00:02, 19.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  87%|████████▋ | 200/230 [00:12<00:01, 19.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  91%|█████████▏| 210/230 [00:13<00:01, 19.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings:  96%|█████████▌| 220/230 [00:13<00:00, 19.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating embeddings: 100%|██████████| 230/230 [00:14<00:00, 16.20it/s]\n"
          ]
        }
      ],
      "source": [
        "vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
        "\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "index = VectorStoreIndex(\n",
        "    nodes=nodes,\n",
        "    storage_context=storage_context, \n",
        "    embed_model=embed_model, \n",
        "    show_progress=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "id": "c8e19705",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "StorageContext(docstore=<llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore object at 0x0000022A6B604350>, index_store=<llama_index.core.storage.index_store.simple_index_store.SimpleIndexStore object at 0x0000022A6B604C90>, vector_stores={'default': FaissVectorStore(stores_text=False, is_embedding_query=True), 'image': <llama_index.core.vector_stores.simple.SimpleVectorStore object at 0x0000022A6B604650>}, graph_store=<llama_index.core.graph_stores.simple.SimpleGraphStore object at 0x0000022A6B605490>)\n"
          ]
        }
      ],
      "source": [
        "print(storage_context)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9d84cc3",
      "metadata": {},
      "source": [
        "### Storing the index on the disk for future use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "id": "07e75b7d",
      "metadata": {},
      "outputs": [],
      "source": [
        "index.storage_context.persist()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fd1e08d",
      "metadata": {},
      "source": [
        "### Loading the index from the disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "47d227a5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:root:Loading llama_index.vector_stores.faiss.base from ./storage\\default__vector_store.json.\n",
            "Loading llama_index.vector_stores.faiss.base from ./storage\\default__vector_store.json.\n",
            "INFO:llama_index.core.indices.loading:Loading all indices.\n",
            "Loading all indices.\n"
          ]
        }
      ],
      "source": [
        "# load index from disk\n",
        "vector_store = FaissVectorStore.from_persist_dir(\"./storage\")\n",
        "storage_context = StorageContext.from_defaults(\n",
        "    vector_store=vector_store, persist_dir=\"./storage\"\n",
        ")\n",
        "index = load_index_from_storage(storage_context=storage_context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "f43fe3a2",
      "metadata": {},
      "outputs": [],
      "source": [
        "retriever = VectorIndexRetriever(\n",
        "    index=index,\n",
        "    similarity_top_k=10,\n",
        ")\n",
        "response_synthesizer = get_response_synthesizer()\n",
        "\n",
        "query_engine = RetrieverQueryEngine(\n",
        "    retriever=retriever,\n",
        "    response_synthesizer=response_synthesizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "fb4b0b60",
      "metadata": {},
      "outputs": [],
      "source": [
        "from llama_index.core.evaluation import FaithfulnessEvaluator\n",
        "evaluator = FaithfulnessEvaluator(llm=llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\"who is the president of india\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "id": "6fa154c7",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "<b>I'm sorry, I cannot answer that question as it is not related to the provided context information about life insurance and personal information.</b>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Markdown(f\"<b>{response}</b>\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "1145e69c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/text-embedding-ada-002/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/gpt-4/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://mathurai.openai.azure.com//openai/deployments/gpt-4/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
          ]
        }
      ],
      "source": [
        "response = query_engine.query(\"what are insurance policies?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "d1b53f90",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "<b>Insurance policies are legal agreements between an individual and an insurance company, guaranteeing the payment of a specified amount upon certain events, such as the policyholder's death. These policies come in various types, including permanent and term life insurance. Permanent life insurance offers coverage for the policyholder's entire lifetime, with variations such as whole life, universal life, and variable life, provided the policy is kept in force. Term life insurance, on the other hand, provides coverage for a specific period, paying out a death benefit only if the policyholder dies within that term. The premiums and benefits of these policies can vary, with some policies offering guarantees on premiums and death benefits for certain periods, adjusting based on investment conditions afterward. Additionally, life insurance benefits are typically tax-free to the beneficiary.</b>"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Markdown(f\"<b>{response}</b>\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67e31eaa",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
